{
    "K": 16,
    "adapter_tune": true,
    "add_adapter_after_attention": false,
    "add_adapter_after_feedforward": true,
    "add_layer_norm_after_adapter": false,
    "add_layer_norm_before_adapter": false,
    "classifier_eval": true,
    "data_dir": "MFTC_set",
    "data_seed": 100,
    "do_eval": true,
    "do_predict": true,
    "do_train": true,
    "epoch": 4.07,
    "eval_accuracy": 34.58799593082401,
    "eval_average": 34.58799593082401,
    "eval_runtime": 436.5323,
    "eval_samples": 983,
    "eval_samples_per_second": 2.252,
    "eval_soft_pet_aggregation": "max",
    "eval_steps": 100,
    "eval_steps_per_second": 0.002,
    "evaluation_strategy": "steps",
    "extra_embd_initializer_range": 0.0001,
    "extra_tokens_init": "verbalizers",
    "extra_without_original": true,
    "greater_is_better": true,
    "learning_rate": 0.0001,
    "load_best_model_at_end": true,
    "mask_position": "1",
    "max_seq_length": 128,
    "max_steps": 1000,
    "metric_for_best_model": "average",
    "model_name_or_path": "roberta-large",
    "output_dir": "outputs-init",
    "overwrite_cache": true,
    "overwrite_output_dir": false,
    "per_device_eval_batch_size": 2000,
    "per_device_train_batch_size": 4,
    "prototypical_eval": false,
    "prototypical_similarity": "euc",
    "save_steps": 100,
    "save_strategy": "steps",
    "save_total_limit": 1,
    "seed": 1,
    "soft_mask_labels_learning_rate": 0.1,
    "soft_pet": true,
    "soft_pet_loss": "extra_tokens",
    "task": "mftc",
    "token_hinge_loss": true,
    "train_in_batch": true,
    "train_loss": 5.377888619959295e-05,
    "train_runtime": 4.3577,
    "train_samples": 983,
    "train_samples_per_second": 917.913,
    "train_steps_per_second": 229.478,
    "tune_layernorms": true
}